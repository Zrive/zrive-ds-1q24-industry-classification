{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: NAICS codes processed successfully. Here's the head of the processed DataFrame:\n",
      "INFO:   NAICS                               BUSINESS_DESCRIPTION\n",
      "0    72  Zenyai Viet Cajun & Pho Restaurant is dedicate...\n",
      "1    54  Kilduff Underground Engineering, Inc. (KUE) is...\n",
      "2    45  024™ is a premium home fragrance brand that de...\n",
      "3    56  Our Services include Office Cleaning Carpet cl...\n",
      "4    62                    NYS Licensed Home Health Agency\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "COVERWALLET_DF_PATH = '../src/data/coverwallet.xlsx'\n",
    "df = pd.read_excel(COVERWALLET_DF_PATH)\n",
    "df = df.dropna()\n",
    "def truncate_naics_and_prepare_data(df, column_name, num_digits):\n",
    "    \"\"\"\n",
    "    Truncates the NAICS codes in the specified column to the desired number of digits and prepares the data.\n",
    "\n",
    "    :param df: pandas DataFrame containing the NAICS codes.\n",
    "    :param column_name: the name of the column with the NAICS codes.\n",
    "    :param num_digits: the number of digits to truncate to.\n",
    "    :return: A modified DataFrame with truncated NAICS codes, and split datasets for training and validation.\n",
    "    \"\"\"\n",
    "    # Validate the number of digits\n",
    "    if not isinstance(num_digits, int) or num_digits <= 0:\n",
    "        logging.error(\"Number of digits must be a positive integer\")\n",
    "        raise ValueError(\"Number of digits must be a positive integer\")\n",
    "\n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Function to truncate or pad NAICS codes\n",
    "    def truncate_code(code):\n",
    "        \"\"\"\n",
    "        Truncates the NAICS code to the specified number of digits.\n",
    "        :param code: the NAICS code to be truncated.\n",
    "        :return: The truncated NAICS code as a string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure the code is a string and truncate if longer than num_digits\n",
    "            return str(code)[:num_digits]\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error truncating code: {code}\")\n",
    "            return code\n",
    "\n",
    "    # Apply the truncation function to the specified column\n",
    "    df_copy[column_name] = df_copy[column_name].apply(truncate_code)\n",
    "\n",
    "    # Ensure all NAICS codes are still strings\n",
    "    df_copy[column_name] = df_copy[column_name].astype(str)\n",
    "\n",
    "    # Add a logging statement to check the result\n",
    "    logging.info(\"NAICS codes processed successfully. Here's the head of the processed DataFrame:\")\n",
    "    logging.info(df_copy.head())\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    df_copy_train, df_copy_val = train_test_split(df_copy, test_size=0.15, shuffle=True, random_state=42)\n",
    "\n",
    "    # Return the processed DataFrame and the split datasets\n",
    "    return df_copy, df_copy_train, df_copy_val\n",
    "'''\n",
    "    # Configuration k-fold\n",
    "    num_folds = 3\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    kfold_datasets = []\n",
    "\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(dataset_train)):\n",
    "        train_dataset = dataset_train.select(train_indices)\n",
    "        val_dataset = dataset_train.select(val_indices)\n",
    "\n",
    "        dataset_dict = {\n",
    "            'train': train_dataset,\n",
    "            'validation': val_dataset\n",
    "        }\n",
    "\n",
    "        features_dict = {\n",
    "            \"NAICS\": dataset_train[\"NAICS\"],\n",
    "            \"BUSINESS_DESCRIPTION\": dataset_train[\"BUSINESS_DESCRIPTION\"],\n",
    "        }\n",
    "\n",
    "        kfold_datasets.append(dataset_dict)\n",
    "        logging.info(f\"Processed fold {fold + 1}\")\n",
    "\n",
    "    for i, dataset_dict in enumerate(kfold_datasets):\n",
    "        for split in dataset_dict.keys():\n",
    "            dataset_dict[split] = dataset_dict[split].map(lambda example: {key: example[key] for key in features_dict.keys()})\n",
    "\n",
    "        logging.info(f\"DatasetDict for Fold {i + 1}:\")\n",
    "        for split, dataset in dataset_dict.items():\n",
    "            logging.info(f\"  {split} split: {dataset}\")\n",
    "\n",
    "    logging.info(\"NAICS codes truncated successfully. Here's the head of the truncated DataFrame:\")\n",
    "    logging.info(\"\\n%s\", df_copy.head())\n",
    "    logging.info(\"Number of unique NAICS labels: %d\", len(labels))\n",
    "    '''\n",
    "    #return df_copy, kfold_datasets, dataset_train, dataset_final_val\n",
    "\n",
    "    #df_2_digits, kfold_2_digits, dataset_train_2_digits, dataset_final_val_2_digits = truncate_naics_and_prepare_data(df, 'NAICS', 2)\n",
    "df_2_digits, dataset_train_2_digits, dataset_final_val_2_digits = truncate_naics_and_prepare_data(df, 'NAICS', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch import nn\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, max_len):\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.texts = np.array(dataframe['BUSINESS_DESCRIPTION'].astype(str))\n",
    "        self.targets = np.array(dataframe['label'])\n",
    "        self.max_len = max_len\n",
    "        self.model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "        # Agregar una capa de clasificación que será la única que entrenemos\n",
    "        self.classifier = nn.Linear(self.model.config.dim, len(np.unique(self.targets)))\n",
    "\n",
    "        # Congelar todos los parámetros del modelo DistilBERT\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Habilitar entrenamiento solo en la capa clasificadora\n",
    "        for param in self.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # Tokenizar el texto y obtener los embeddings con el modelo DistilBERT\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=self.max_len)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "        # Obtener los embeddings del token [CLS] (última capa oculta)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # Embeddings del token [CLS]\n",
    "\n",
    "        # Aquí simplemente extraemos los embeddings después de haber sido procesados por la capa de clasificación,\n",
    "        # pero no utilizamos los logits para clasificación directa en este paso.\n",
    "        # Si deseas ver el efecto de la capa clasificadora, podrías calcular los logits y luego ignorarlos:\n",
    "        logits = self.classifier(embeddings)  # Esto entrenará la capa con los gradientes apropiados durante el entrenamiento\n",
    "\n",
    "        label = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            'embeddings': embeddings,  # Devolver embeddings del token [CLS]\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05\n",
    "train_size = 0.7\n",
    "test_size = 0.2\n",
    "val_size = 0.1\n",
    "df_2_digits.rename(columns={'NAICS': 'label'}, inplace=True)\n",
    "df_2_digits['label'], _ = pd.factorize(df_2_digits['label'])\n",
    "train_data = df_2_digits.sample(frac=train_size, random_state=200)\n",
    "remaining_data = df_2_digits.drop(train_data.index).reset_index(drop=True)\n",
    "test_data = remaining_data.sample(frac=test_size / (test_size + val_size), random_state=200)\n",
    "val_data = remaining_data.drop(test_data.index).reset_index(drop=True)\n",
    "\n",
    "def dataset_to_dataframe(dataset):\n",
    "    data = []\n",
    "    for i in range(len(dataset)):\n",
    "        item = dataset[i]\n",
    "        # Assume each item returns a dictionary with 'embeddings' and 'label'\n",
    "        embeddings = item['embeddings'].numpy()  # Converting tensor to numpy array\n",
    "        label = item['label'].item()  # Getting the scalar value of the label tensor\n",
    "        # You may want to store more meaningful data depending on your application\n",
    "        # For demonstration, we'll just store the label and the shape of the embeddings\n",
    "        data.append({\n",
    "            'label': label,\n",
    "            'embeddings': embeddings  # Storing just the shape for simplicity\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Assuming the CustomDataset, MAX_LEN, and other variables are set up properly\n",
    "\n",
    "\n",
    "training_set = CustomDataset(train_data, MAX_LEN)\n",
    "test_set = CustomDataset(test_data, MAX_LEN)\n",
    "val_set = CustomDataset(val_data, MAX_LEN)\n",
    "\n",
    "# Convert datasets to DataFrames\n",
    "df_training = dataset_to_dataframe(training_set)\n",
    "df_test = dataset_to_dataframe(test_set)\n",
    "df_val = dataset_to_dataframe(val_set)\n",
    "\n",
    "logging.info(\"TRAIN Dataset: %s\", df_training.head())\n",
    "logging.info(\"TEST Dataset: %s\", df_test.head())\n",
    "logging.info(\"VALIDATION Dataset: %s\", df_val.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import logging\n",
    "\n",
    "# Configurar logging para mostrar información de las métricas\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Supongamos que df_training, df_test, y df_val ya están definidos y cargados\n",
    "# Aplanar los embeddings y extraer las etiquetas\n",
    "X_train = np.stack(df_training['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_train = df_training['label'].to_numpy()\n",
    "\n",
    "X_test = np.stack(df_test['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_test = df_test['label'].to_numpy()\n",
    "\n",
    "X_val = np.stack(df_val['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_val = df_val['label'].to_numpy()\n",
    "\n",
    "# Entrenar el modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de validación\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_proba = model.decision_function(X_val)  # Obtener las puntuaciones de decisión para calcular las curvas de precisión-recall\n",
    "\n",
    "# Matriz de confusión y reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "report = classification_report(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "logging.info(\"F1 Score: %f\", f1)\n",
    "\n",
    "# Binarizar las etiquetas en un formato one-vs-all\n",
    "y_val_binarized = label_binarize(y_val, classes=np.unique(y_val))\n",
    "\n",
    "# Calcular precisión y recall para cada clase\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(len(np.unique(y_val))):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_val_binarized[:, i], y_val_proba[:, i])\n",
    "    average_precision[i] = average_precision_score(y_val_binarized[:, i], y_val_proba[:, i])\n",
    "\n",
    "# Graficar la curva de precisión-recall para cada clase\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(np.unique(y_val))))\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, color in zip(range(len(np.unique(y_val))), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label='Class {0} (AP={1:0.2f})'.format(i, average_precision[i]))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve for each class')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import logging\n",
    "\n",
    "# Configurar logging para mostrar información de las métricas\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Supongamos que df_training, df_test, y df_val ya están definidos y cargados\n",
    "# Aplanar los embeddings y extraer las etiquetas\n",
    "X_train = np.stack(df_training['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_train = df_training['label'].to_numpy()\n",
    "\n",
    "X_test = np.stack(df_test['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_test = df_test['label'].to_numpy()\n",
    "\n",
    "X_val = np.stack(df_val['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_val = df_val['label'].to_numpy()\n",
    "\n",
    "# Entrenar el modelo de Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de validación\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_proba = model.predict_proba(X_val)  # Usar predict_proba para Random Forest\n",
    "\n",
    "# Matriz de confusión y reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "report = classification_report(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report Random Forest:\\n\", report)\n",
    "logging.info(\"F1 Score: %f\", f1)\n",
    "\n",
    "# Binarizar las etiquetas en un formato one-vs-all\n",
    "y_val_binarized = label_binarize(y_val, classes=np.unique(y_val))\n",
    "\n",
    "# Calcular precisión y recall para cada clase usando predict_proba\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(len(np.unique(y_val))):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_val_binarized[:, i], y_val_proba[:, i])\n",
    "    average_precision[i] = average_precision_score(y_val_binarized[:, i], y_val_proba[:, i])\n",
    "\n",
    "# Graficar la curva de precisión-recall para cada clase\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(np.unique(y_val))))\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, color in zip(range(len(np.unique(y_val))), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label='Class {0} (AP={1:0.2f})'.format(i, average_precision[i]))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve for each class')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, average_precision_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import logging\n",
    "\n",
    "# Configurar logging para mostrar información de las métricas\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Aplanar los embeddings y extraer las etiquetas\n",
    "X_train = np.stack(df_training['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_train = df_training['label'].to_numpy()\n",
    "\n",
    "X_test = np.stack(df_test['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_test = df_test['label'].to_numpy()\n",
    "\n",
    "X_val = np.stack(df_val['embeddings'].apply(lambda x: np.array(x).flatten()))\n",
    "y_val = df_val['label'].to_numpy()\n",
    "\n",
    "# Entrenar el modelo SVM\n",
    "model = SVC(probability=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones en el conjunto de validación\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_proba = model.predict_proba(X_val)  # SVM también puede proporcionar probabilidades\n",
    "\n",
    "# Matriz de confusión y reporte de clasificación\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "report = classification_report(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report SVM:\\n\", report)\n",
    "logging.info(\"F1 Score SVM: %f\", f1)\n",
    "\n",
    "'''\n",
    "# Binarizar las etiquetas en un formato one-vs-all para SVM\n",
    "y_val_binarized = label_binarize(y_val, classes=np.unique(y_val))\n",
    "\n",
    "# Calcular precisión y recall para cada clase usando predict_proba de SVM\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(len(np.unique(y_val))):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_val_binarized[:, i], y_val_proba[:, i])\n",
    "    average_precision[i] = average_precision_score(y_val_binarized[:, i], y_val_proba[:, i])\n",
    "\n",
    "# Graficar la curva de precisión-recall para cada clase de SVM\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(np.unique(y_val))))\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, color in zip(range(len(np.unique(y_val))), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=2,\n",
    "             label='Class {0} (AP={1:0.2f})'.format(i, average_precision[i]))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve for each class using SVM')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "#USA ESTE CODIGO Y ADAPTALO PARA RANDOM FOREST Y PARA LOGISTIC REGRESSION. LITERLAMENTE\n",
    "#ADAPTA EL CODIGO ENTERO PARA DECISION TREES,GBM,CLASSIFIER CHAIN (PARA TENER CORRELACION ENTRE CADENAS)\n",
    "\n",
    "y_val_binarized = label_binarize(y_val, classes=np.unique(y_val))\n",
    "\n",
    "# Calcular precisión y recall para cada clase usando predict_proba\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "thresholds = dict()\n",
    "\n",
    "for i in range(len(np.unique(y_val))):\n",
    "    precision[i], recall[i], thresholds[i] = precision_recall_curve(y_val_binarized[:, i], y_val_proba[:, i])\n",
    "    average_precision[i] = average_precision_score(y_val_binarized[:, i], y_val_proba[:, i])\n",
    "\n",
    "# Graficar la curva de precisión-recall para cada clase\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Establecer el \"ciclo\" de colores para que coincida con el número de clases\n",
    "colors = cycle(plt.cm.viridis(np.linspace(0, 1, len(np.unique(y_val)))))\n",
    "\n",
    "f1_scores = []\n",
    "for i, color in zip(range(len(np.unique(y_val))), colors):\n",
    "    plt.plot(recall[i], precision[i], color=color, lw=1,\n",
    "             label='Class {0} (AP={1:0.2f})'.format(i, average_precision[i]))\n",
    "    f1 = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "    f1_scores.append(f1[np.argmax(f1)])\n",
    "\n",
    "# Calcular la precisión y el recall promedios (micro-average)\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_val_binarized.ravel(), y_val_proba.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_val_binarized, y_val_proba, average=\"micro\")\n",
    "\n",
    "# Graficar la curva de precisión-recall promedio\n",
    "plt.plot(recall[\"micro\"], precision[\"micro\"],\n",
    "         label='Micro-average Precision-Recall (AP={0:0.2f})'.format(average_precision[\"micro\"]),\n",
    "         color='gold', linestyle=':', linewidth=4)\n",
    "\n",
    "# Añadir el F1-score promedio al logging\n",
    "f1_average = np.mean(f1_scores)\n",
    "logging.info(\"Average F1 Score SVM: %f\", f1_average)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve for each class and micro-average')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zrive-ds-O6CSjbdk-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

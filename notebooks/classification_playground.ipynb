{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistilBertTokenizer, DistilBertModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import DistilBertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "COVERWALLET_DF_PATH = 'coverwallet.xlsx'\n",
    "df = pd.read_excel(COVERWALLET_DF_PATH)\n",
    "df = df.dropna()\n",
    "def truncate_naics_and_prepare_data(df, column_name, num_digits):\n",
    "    \"\"\"\n",
    "    Truncates the NAICS codes in the specified column to the desired number of digits and prepares the data.\n",
    "\n",
    "    :param df: pandas DataFrame containing the NAICS codes.\n",
    "    :param column_name: the name of the column with the NAICS codes.\n",
    "    :param num_digits: the number of digits to truncate to.\n",
    "    :return: A modified DataFrame with truncated NAICS codes, and split datasets for training and validation.\n",
    "    \"\"\"\n",
    "    # Validate the number of digits\n",
    "    if not isinstance(num_digits, int) or num_digits <= 0:\n",
    "        logging.error(\"Number of digits must be a positive integer\")\n",
    "        raise ValueError(\"Number of digits must be a positive integer\")\n",
    "\n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Function to truncate or pad NAICS codes\n",
    "    def truncate_code(code):\n",
    "        \"\"\"\n",
    "        Truncates the NAICS code to the specified number of digits.\n",
    "        :param code: the NAICS code to be truncated.\n",
    "        :return: The truncated NAICS code as a string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure the code is a string and truncate if longer than num_digits\n",
    "            return str(code)[:num_digits]\n",
    "        except Exception as e:\n",
    "            logging.exception(f\"Error truncating code: {code}\")\n",
    "            return code\n",
    "\n",
    "    # Apply the truncation function to the specified column\n",
    "    df_copy[column_name] = df_copy[column_name].apply(truncate_code)\n",
    "\n",
    "    # Ensure all NAICS codes are still strings\n",
    "    df_copy[column_name] = df_copy[column_name].astype(str)\n",
    "\n",
    "    # Add a logging statement to check the result\n",
    "    logging.info(\"NAICS codes processed successfully. Here's the head of the processed DataFrame:\")\n",
    "    logging.info(df_copy.head())\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    df_copy_train, df_copy_val = train_test_split(df_copy, test_size=0.15, shuffle=True, random_state=42)\n",
    "\n",
    "    # Return the processed DataFrame and the split datasets\n",
    "    return df_copy, df_copy_train, df_copy_val\n",
    "'''\n",
    "    # Configuration k-fold\n",
    "    num_folds = 3\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    kfold_datasets = []\n",
    "\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(dataset_train)):\n",
    "        train_dataset = dataset_train.select(train_indices)\n",
    "        val_dataset = dataset_train.select(val_indices)\n",
    "\n",
    "        dataset_dict = {\n",
    "            'train': train_dataset,\n",
    "            'validation': val_dataset\n",
    "        }\n",
    "\n",
    "        features_dict = {\n",
    "            \"NAICS\": dataset_train[\"NAICS\"],\n",
    "            \"BUSINESS_DESCRIPTION\": dataset_train[\"BUSINESS_DESCRIPTION\"],\n",
    "        }\n",
    "\n",
    "        kfold_datasets.append(dataset_dict)\n",
    "        logging.info(f\"Processed fold {fold + 1}\")\n",
    "\n",
    "    for i, dataset_dict in enumerate(kfold_datasets):\n",
    "        for split in dataset_dict.keys():\n",
    "            dataset_dict[split] = dataset_dict[split].map(lambda example: {key: example[key] for key in features_dict.keys()})\n",
    "\n",
    "        logging.info(f\"DatasetDict for Fold {i + 1}:\")\n",
    "        for split, dataset in dataset_dict.items():\n",
    "            logging.info(f\"  {split} split: {dataset}\")\n",
    "\n",
    "    logging.info(\"NAICS codes truncated successfully. Here's the head of the truncated DataFrame:\")\n",
    "    logging.info(\"\\n%s\", df_copy.head())\n",
    "    logging.info(\"Number of unique NAICS labels: %d\", len(labels))\n",
    "    '''\n",
    "    #return df_copy, kfold_datasets, dataset_train, dataset_final_val\n",
    "\n",
    "    #df_2_digits, kfold_2_digits, dataset_train_2_digits, dataset_final_val_2_digits = truncate_naics_and_prepare_data(df, 'NAICS', 2)\n",
    "df_2_digits, dataset_train_2_digits, dataset_final_val_2_digits = truncate_naics_and_prepare_data(df, 'NAICS', 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zrive-ds-O6CSjbdk-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

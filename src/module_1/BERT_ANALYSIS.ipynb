{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBRARIES LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edu/.cache/pypoetry/virtualenvs/zrive-ds-J_lydEot-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, DistilBertTokenizer\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach will be very useful not only for going step byu step with the classification but also for allowing to decide the trade-off of accuracy and digits returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/coverwallet.xlsx'\n",
    "df = pd.read_excel(data_path)\n",
    "df = df.dropna()\n",
    "def truncate_naics_and_prepare_data(df, column_name, num_digits):\n",
    "    \"\"\"\n",
    "    Truncates the NAICS codes in the specified column to the desired number of digits.\n",
    "\n",
    "    :param df: pandas DataFrame containing the NAICS codes.\n",
    "    :param column_name: the name of the column with the NAICS codes.\n",
    "    :param num_digits: the number of digits to truncate to.\n",
    "    :return: A copy of the DataFrame with the NAICS codes truncated.\n",
    "    \"\"\"\n",
    "    # Validate the number of digits\n",
    "    if not isinstance(num_digits, int) or num_digits <= 0:\n",
    "        logging.error(\"Number of digits must be a positive integer\")\n",
    "        raise ValueError(\"Number of digits must be a positive integer\")\n",
    "    \n",
    "    # Make a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    def truncate_code(code):\n",
    "        \"\"\"\n",
    "        Truncates or pads the NAICS code to the specified number of digits.\n",
    "        :param code: the NAICS code to be truncated.\n",
    "        :return: The truncated or original NAICS code as a string.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure the code is a string\n",
    "            code_str = str(code)\n",
    "            # Truncate the code if it's longer than num_digits\n",
    "            return code_str[:num_digits].ljust(num_digits, '0')\n",
    "        except Exception as e:\n",
    "            logging.exception(\"Error truncating code: {}\".format(code))\n",
    "            return code\n",
    "        \n",
    "    # Apply the truncation function to the specified column\n",
    "    df_copy[column_name] = df_copy[column_name].apply(truncate_code)\n",
    "    # Try to convert the truncated column to integers\n",
    "    try:\n",
    "        df_copy[column_name] = df_copy[column_name].astype(int)\n",
    "    except ValueError as e:\n",
    "        logging.warning(\"Could not convert truncated codes to integers: {}\".format(e))\n",
    "        # Keep the column as strings if conversion fails\n",
    "        pass\n",
    "    \n",
    "    labels = df_copy['NAICS'].unique().tolist()\n",
    "    id2label = {idx: label for idx, label in enumerate(labels)}\n",
    "    label2id = {label: idx for idx, label in enumerate(labels)}\n",
    "    df_copy['label'] = df_copy['NAICS'].map(label2id)\n",
    "    logging.info(\"NAICS codes processed successfully. Here's the head of the processed DataFrame:\")\n",
    "    logging.info(\"\\n%s\", df_copy.head())\n",
    "    df_copy_train, df_copy_final_val = train_test_split(df_copy, test_size=0.15, shuffle=True, random_state=42)\n",
    "    \n",
    "    dataset_train = Dataset.from_pandas(df_copy_train)\n",
    "    dataset_final_val = Dataset.from_pandas(df_copy_final_val)\n",
    "\n",
    "# Configuration k-fold\n",
    "    num_folds = 3\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    kfold_datasets = []\n",
    "\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(dataset_train)):\n",
    "        train_dataset = dataset_train.select(train_indices)\n",
    "        val_dataset = dataset_train.select(val_indices)\n",
    "        \n",
    "        dataset_dict = {\n",
    "            'train': train_dataset,\n",
    "            'validation': val_dataset\n",
    "        }\n",
    "\n",
    "        features_dict = {\n",
    "            \"NAICS\": dataset_train[\"NAICS\"],\n",
    "            \"BUSINESS_DESCRIPTION\": dataset_train[\"BUSINESS_DESCRIPTION\"],\n",
    "        }\n",
    "    \n",
    "        kfold_datasets.append(dataset_dict)\n",
    "        logging.info(f\"Processed fold {fold + 1}\")\n",
    "\n",
    "    for i, dataset_dict in enumerate(kfold_datasets):\n",
    "        for split in dataset_dict.keys():\n",
    "            dataset_dict[split] = dataset_dict[split].map(lambda example: {key: example[key] for key in features_dict.keys()})\n",
    "\n",
    "        logging.info(f\"DatasetDict for Fold {i + 1}:\")\n",
    "        for split, dataset in dataset_dict.items():\n",
    "            logging.info(f\"  {split} split: {dataset}\")\n",
    "            \n",
    "    logging.info(\"NAICS codes truncated successfully. Here's the head of the truncated DataFrame:\")\n",
    "    logging.info(\"\\n%s\", df_copy.head())\n",
    "    logging.info(\"Number of unique NAICS labels: %d\", len(labels))\n",
    "\n",
    "    return df_copy, kfold_datasets, dataset_train, dataset_final_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: NAICS codes processed successfully. Here's the head of the processed DataFrame:\n",
      "INFO: \n",
      "   NAICS                               BUSINESS_DESCRIPTION  label\n",
      "0     72  Zenyai Viet Cajun & Pho Restaurant is dedicate...      0\n",
      "1     54  Kilduff Underground Engineering, Inc. (KUE) is...      1\n",
      "2     45  024™ is a premium home fragrance brand that de...      2\n",
      "3     56  Our Services include Office Cleaning Carpet cl...      3\n",
      "4     62                    NYS Licensed Home Health Agency      4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Processed fold 1\n",
      "INFO: Processed fold 2\n",
      "INFO: Processed fold 3\n",
      "Map: 100%|██████████| 8032/8032 [00:00<00:00, 9408.72 examples/s]\n",
      "Map: 100%|██████████| 4016/4016 [00:00<00:00, 10147.58 examples/s]\n",
      "INFO: DatasetDict for Fold 1:\n",
      "INFO:   train split: Dataset({\n",
      "    features: ['NAICS', 'BUSINESS_DESCRIPTION', 'label', '__index_level_0__'],\n",
      "    num_rows: 8032\n",
      "})\n",
      "INFO:   validation split: Dataset({\n",
      "    features: ['NAICS', 'BUSINESS_DESCRIPTION', 'label', '__index_level_0__'],\n",
      "    num_rows: 4016\n",
      "})\n",
      "Map: 100%|██████████| 8032/8032 [00:00<00:00, 9520.51 examples/s] \n",
      "Map: 100%|██████████| 4016/4016 [00:00<00:00, 8953.38 examples/s] \n",
      "INFO: DatasetDict for Fold 2:\n",
      "INFO:   train split: Dataset({\n",
      "    features: ['NAICS', 'BUSINESS_DESCRIPTION', 'label', '__index_level_0__'],\n",
      "    num_rows: 8032\n",
      "})\n",
      "INFO:   validation split: Dataset({\n",
      "    features: ['NAICS', 'BUSINESS_DESCRIPTION', 'label', '__index_level_0__'],\n",
      "    num_rows: 4016\n",
      "})\n",
      "Map: 100%|██████████| 8032/8032 [00:00<00:00, 8838.67 examples/s]\n",
      "Map: 100%|██████████| 4016/4016 [00:00<00:00, 10226.58 examples/s]\n",
      "INFO: DatasetDict for Fold 3:\n",
      "INFO:   train split: Dataset({\n",
      "    features: ['NAICS', 'BUSINESS_DESCRIPTION', 'label', '__index_level_0__'],\n",
      "    num_rows: 8032\n",
      "})\n",
      "INFO:   validation split: Dataset({\n",
      "    features: ['NAICS', 'BUSINESS_DESCRIPTION', 'label', '__index_level_0__'],\n",
      "    num_rows: 4016\n",
      "})\n",
      "INFO: NAICS codes truncated successfully. Here's the head of the truncated DataFrame:\n",
      "INFO: \n",
      "   NAICS                               BUSINESS_DESCRIPTION  label\n",
      "0     72  Zenyai Viet Cajun & Pho Restaurant is dedicate...      0\n",
      "1     54  Kilduff Underground Engineering, Inc. (KUE) is...      1\n",
      "2     45  024™ is a premium home fragrance brand that de...      2\n",
      "3     56  Our Services include Office Cleaning Carpet cl...      3\n",
      "4     62                    NYS Licensed Home Health Agency      4\n",
      "INFO: Number of unique NAICS labels: 24\n"
     ]
    }
   ],
   "source": [
    "df_2_digits, kfold_2_digits, dataset_train_2_digits, dataset_final_val_2_digits = truncate_naics_and_prepare_data(df, 'NAICS', 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zrive-ds-J_lydEot-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
